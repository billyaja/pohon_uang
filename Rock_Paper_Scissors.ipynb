{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billyaja/pohon_uang/blob/main/Rock_Paper_Scissors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nama**   : Billy Erickson Samosir\n",
        "\n",
        "**email**  : billy.samosir17@gmail.com\n",
        "\n",
        "**Hp**     : +6285246308149\n",
        "\n",
        "**Asal Kota** : Humbang Hasundutan, Sumatera Utara\n"
      ],
      "metadata": {
        "id": "9t58BuM5fZgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "**Library yang dibutuhkan**"
      ],
      "metadata": {
        "id": "LNCU-hUDbf36"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NnU6C202L74d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pengambilan dataset rockpaperscissor**"
      ],
      "metadata": {
        "id": "zTNBl8L2bpyC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eAiCLWLMUp-",
        "outputId": "dbc26952-6790-4a7b-c05e-5471842491f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-26 09:54:33--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221126T095433Z&X-Amz-Expires=300&X-Amz-Signature=7594392b24abd8c39a0c3036def8d49930d32a736f115e0cd9dddfacc1120b9c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-26 09:54:33--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221126T095433Z&X-Amz-Expires=300&X-Amz-Signature=7594392b24abd8c39a0c3036def8d49930d32a736f115e0cd9dddfacc1120b9c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M   176MB/s    in 1.7s    \n",
            "\n",
            "2022-11-26 09:54:35 (176 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# pengambilan dataset rockpaperscissor\n",
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpr3BchRMvZa"
      },
      "outputs": [],
      "source": [
        "import zipfile, os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeuEJVcUmFUM"
      },
      "outputs": [],
      "source": [
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        " \n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHlgbsCvn-pM",
        "outputId": "43d05f14-5c9c-4153-fd7c-eb04ad1d551b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['paper', 'scissors', 'README_rpc-cv-images.txt', 'rock']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.listdir(base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penggunaan Image Data Generator"
      ],
      "metadata": {
        "id": "Y95jfE-XbvpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UimUwLHHn_G9"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'wrap',\n",
        "                    validation_split=0.4) ## Ukuran validation set adalah 40%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4aEYEfMoAuc",
        "outputId": "dd19f824-8b36-44b4-e6e0-9e8b534662f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        base_dir,\n",
        "        target_size=(150, 150), \n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        subset='training')\n",
        " \n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        base_dir,\n",
        "        target_size=(150, 150),\n",
        "        class_mode='categorical',\n",
        "        subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import time module**\n",
        "\n",
        "_Module ini akan digunakan untuk mengukur waktu yang dibutuhkan pada proses model fitting_"
      ],
      "metadata": {
        "id": "z-G_kZ-Vb0Fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsXCbtfU07K0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF8Ph3RjoCME"
      },
      "outputs": [],
      "source": [
        "# penggunaan model Sequential untuk membangun CNN\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Agumentasi Gambar\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5), # untuk menghindari dari overfitting dan mempercepat running time\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSWQ-6nnoDq_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kYKy0mCoFYa",
        "outputId": "96816864-4c0d-4e08-908d-2700c48a11b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 47s - loss: 1.1610 - accuracy: 0.3812 - val_loss: 1.0534 - val_accuracy: 0.4062 - 47s/epoch - 2s/step\n",
            "Epoch 2/20\n",
            "25/25 - 43s - loss: 0.9912 - accuracy: 0.4948 - val_loss: 0.8826 - val_accuracy: 0.6562 - 43s/epoch - 2s/step\n",
            "Epoch 3/20\n",
            "25/25 - 43s - loss: 0.8632 - accuracy: 0.6039 - val_loss: 0.7178 - val_accuracy: 0.7375 - 43s/epoch - 2s/step\n",
            "Epoch 4/20\n",
            "25/25 - 45s - loss: 0.7289 - accuracy: 0.6922 - val_loss: 0.5674 - val_accuracy: 0.7625 - 45s/epoch - 2s/step\n",
            "Epoch 5/20\n",
            "25/25 - 44s - loss: 0.4855 - accuracy: 0.8273 - val_loss: 0.3775 - val_accuracy: 0.8438 - 44s/epoch - 2s/step\n",
            "Epoch 6/20\n",
            "25/25 - 47s - loss: 0.3116 - accuracy: 0.9000 - val_loss: 0.2929 - val_accuracy: 0.9375 - 47s/epoch - 2s/step\n",
            "Epoch 7/20\n",
            "25/25 - 43s - loss: 0.2279 - accuracy: 0.9234 - val_loss: 0.1495 - val_accuracy: 0.9438 - 43s/epoch - 2s/step\n",
            "Epoch 8/20\n",
            "25/25 - 43s - loss: 0.1796 - accuracy: 0.9364 - val_loss: 0.1963 - val_accuracy: 0.9125 - 43s/epoch - 2s/step\n",
            "Epoch 9/20\n",
            "25/25 - 43s - loss: 0.2112 - accuracy: 0.9221 - val_loss: 0.1906 - val_accuracy: 0.9125 - 43s/epoch - 2s/step\n",
            "Epoch 10/20\n",
            "25/25 - 45s - loss: 0.1617 - accuracy: 0.9488 - val_loss: 0.0944 - val_accuracy: 0.9812 - 45s/epoch - 2s/step\n",
            "Epoch 11/20\n",
            "25/25 - 43s - loss: 0.1215 - accuracy: 0.9584 - val_loss: 0.0827 - val_accuracy: 0.9750 - 43s/epoch - 2s/step\n",
            "Epoch 12/20\n",
            "25/25 - 43s - loss: 0.0746 - accuracy: 0.9805 - val_loss: 0.1284 - val_accuracy: 0.9563 - 43s/epoch - 2s/step\n",
            "Epoch 13/20\n",
            "25/25 - 43s - loss: 0.1077 - accuracy: 0.9597 - val_loss: 0.0558 - val_accuracy: 0.9812 - 43s/epoch - 2s/step\n",
            "Epoch 14/20\n",
            "25/25 - 44s - loss: 0.0710 - accuracy: 0.9831 - val_loss: 0.1008 - val_accuracy: 0.9812 - 44s/epoch - 2s/step\n",
            "Epoch 15/20\n",
            "25/25 - 43s - loss: 0.0747 - accuracy: 0.9753 - val_loss: 0.0729 - val_accuracy: 0.9750 - 43s/epoch - 2s/step\n",
            "Epoch 16/20\n",
            "25/25 - 43s - loss: 0.1585 - accuracy: 0.9519 - val_loss: 0.1022 - val_accuracy: 0.9750 - 43s/epoch - 2s/step\n",
            "Epoch 17/20\n",
            "25/25 - 43s - loss: 0.0954 - accuracy: 0.9740 - val_loss: 0.1614 - val_accuracy: 0.9438 - 43s/epoch - 2s/step\n",
            "Epoch 18/20\n",
            "25/25 - 43s - loss: 0.0866 - accuracy: 0.9701 - val_loss: 0.1714 - val_accuracy: 0.9438 - 43s/epoch - 2s/step\n",
            "Epoch 19/20\n",
            "25/25 - 46s - loss: 0.0497 - accuracy: 0.9862 - val_loss: 0.1305 - val_accuracy: 0.9625 - 46s/epoch - 2s/step\n",
            "Epoch 20/20\n",
            "25/25 - 43s - loss: 0.0506 - accuracy: 0.9883 - val_loss: 0.0171 - val_accuracy: 0.9937 - 43s/epoch - 2s/step\n",
            "The time of execution of above program is : 21.59535057147344 minutes\n"
          ]
        }
      ],
      "source": [
        "# record start time\n",
        "start = time.time()\n",
        "\n",
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=5,\n",
        "      verbose=2)\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        "\n",
        "# print the difference between start\n",
        "# and end time in milli. secs\n",
        "print(\"The time of execution of above program is :\",\n",
        "      ((end-start) * 10**3)/60000, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "j86_gjFQVdlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = tf.keras.utils.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  if classes[0][0]==1:\n",
        "    print('paper')\n",
        "  elif classes[0][1]==1:\n",
        "    print('rock')\n",
        "  elif classes[0][2]==1:\n",
        "    print('scissors')\n",
        "  else:\n",
        "    print('unknown')"
      ],
      "metadata": {
        "id": "7M9Gt505cKbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqvAMfGiaugCc1XNCRmBIy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}